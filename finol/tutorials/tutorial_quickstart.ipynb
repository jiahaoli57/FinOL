{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Quick Introduction to FinOL\n",
    "\n",
    "This Jupyter notebook goes through the basic usage of FinOL.\n",
    "\n",
    "- Install FinOL\n",
    "- Complete the whole data-training-testing process involves\n",
    "  - Read train/valid/test data\n",
    "  - Define and optimize model\n",
    "  - Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install FinOL and additional dependencies\n",
    "\n",
    "``FinOL`` can be installed via `pip` or from the master branch of Git repository.\n",
    "Most of the dependencies required by ``FinOL`` are automatically installed when using\n",
    " the provided pyproject.toml file. HHowever, specific dependencies like ``TA-Lib``\n",
    " require separate installation as it is a library with C/C++ bindings.\n",
    "\n",
    "In the code snippet below, you can see the method to install ``TA-Lib`` in a Colab environment.\n",
    "For users running ``FinOL`` on Windows, Linux, or Mac, please refer to our official documentation for\n",
    "detailed installation instructions. The documentation outlines how to install ``FinOL`` completely, including ``TA-Lib``."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# install finol and most dependencies\n",
    "!pip install finol\n",
    "\n",
    "# install ta-lib\n",
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "!tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "import os\n",
    "os.chdir('ta-lib')\n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "os.chdir('../')\n",
    "!pip install TA-Lib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import finol\n",
    "\n",
    "finol.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quickstart: command line usage\n",
    "\n",
    "Before running the above commands, users can first configure some parameters through the config file to customize the usage according to their needs. For example, setting the device to CPU, selecting a different dataset, adjusting the data preprocessing parameters, and choosing a different model, etc. The specific configuration method is as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from finol.utils import load_config, update_config\n",
    "\n",
    "config = load_config()\n",
    "config[\"DEVICE\"] = \"cpu\"\n",
    "config[\"DATASET_NAME\"] = \"DJIA\"\n",
    "config[\"DATA_AUGMENTATION_CONFIG\"][\"WINDOW_DATA\"][\"WINDOW_SIZE\"] = 15\n",
    "config[\"SCALER\"] = \"WindowMinMaxScaler\"\n",
    "config[\"MODEL_NAME\"] = \"DNN\"\n",
    "config[\"TUNE_PARAMETERS\"] = True\n",
    "update_config(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train_loader': <torch.utils.data.dataloader.DataLoader at 0x2e77fea0d30>,\n 'val_loader': <torch.utils.data.dataloader.DataLoader at 0x2e77feb57f0>,\n 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x2e77feb5af0>,\n 'NUM_TRAIN_PERIODS': 3293,\n 'NUM_VAL_PERIODS': 1130,\n 'NUM_TEST_PERIODS': 1131,\n 'NUM_ASSETS': 26,\n 'NUM_FEATURES_AUGMENTED': 1430,\n 'NUM_FEATURES_ORIGINAL': 143,\n 'DETAILED_NUM_FEATURES': {'OHLCV_FEATURES': 5,\n  'OVERLAP_FEATURES': 20,\n  'MOMENTUM_FEATURES': 40,\n  'VOLUME_FEATURES': 3,\n  'CYCLE_FEATURES': 7,\n  'PRICE_FEATURES': 4,\n  'VOLATILITY_FEATURES': 3,\n  'PATTERN_FEATURES': 61},\n 'WINDOW_SIZE': 10,\n 'OVERALL_FEATURE_LIST': ['OHLCV_FEATURES',\n  'OVERLAP_FEATURES',\n  'MOMENTUM_FEATURES',\n  'VOLUME_FEATURES',\n  'CYCLE_FEATURES',\n  'PRICE_FEATURES',\n  'VOLATILITY_FEATURES',\n  'PATTERN_FEATURES'],\n 'DETAILED_FEATURE_LIST': ['OPEN',\n  'HIGH',\n  'LOW',\n  'CLOSE',\n  'VOLUME',\n  'BBANDS_UPPER',\n  'BBANDS_MIDDLE',\n  'BBANDS_LOWER',\n  'DEMA',\n  'EMA',\n  'HT_TRENDLINE',\n  'KAMA',\n  'MA',\n  'MAMA',\n  'MAMA_FAMA',\n  'MAVP',\n  'MIDPOINT',\n  'MIDPRICE',\n  'SAR',\n  'SAREXT',\n  'SMA',\n  'T3',\n  'TEMA',\n  'TRIMA',\n  'WMA',\n  'ADX',\n  'ADXR',\n  'APO',\n  'AROON_UP',\n  'AROON_DOWN',\n  'AROONOSC',\n  'BOP',\n  'CCI',\n  'CMO',\n  'DX',\n  'MACD',\n  'MACD_SIGNAL',\n  'MACD_HIST',\n  'MACDEXT',\n  'MACDEXT_SIGNAL',\n  'MACDEXT_HIST',\n  'MACDFIX',\n  'MACDFIX_SIGNAL',\n  'MACDFIX_HIST',\n  'MFI',\n  'MINUS_DI',\n  'MINUS_DM',\n  'MOM',\n  'PLUS_DI',\n  'PLUS_DM',\n  'PPO',\n  'ROC',\n  'ROCP',\n  'ROCR',\n  'ROCR100',\n  'RSI',\n  'STOCH_K',\n  'STOCH_D',\n  'STOCHF_K',\n  'STOCHF_D',\n  'STOCHRSI_K',\n  'STOCHRSI_D',\n  'TRIX',\n  'ULTOSC',\n  'WILLR',\n  'AD',\n  'ADOSC',\n  'OBV',\n  'HT_DCPERIOD',\n  'HT_DCPHASE',\n  'HT_PHASOR_INPHASE',\n  'HT_PHASOR_QUADRATURE',\n  'HT_SINE_LEADSINE',\n  'HT_SINE_SINEWAVE',\n  'HT_TRENDMODE',\n  'AVGPRICE',\n  'MEDPRICE',\n  'TYPPRICE',\n  'WCLPRICE',\n  'ATR',\n  'NATR',\n  'TRANGE',\n  'CDL2CROWS',\n  'CDL3BLACKCROWS',\n  'CDL3INSIDE',\n  'CDL3LINESTRIKE',\n  'CDL3OUTSIDE',\n  'CDL3STARSINSOUTH',\n  'CDL3WHITESOLDIERS',\n  'CDLABANDONEDBABY',\n  'CDLADVANCEBLOCK',\n  'CDLBELTHOLD',\n  'CDLBREAKAWAY',\n  'CDLCLOSINGMARUBOZU',\n  'CDLCONCEALBABYSWALL',\n  'CDLCOUNTERATTACK',\n  'CDLDARKCLOUDCOVER',\n  'CDLDOJI',\n  'CDLDOJISTAR',\n  'CDLDRAGONFLYDOJI',\n  'CDLENGULFING',\n  'CDLEVENINGDOJISTAR',\n  'CDLEVENINGSTAR',\n  'CDLGAPSIDESIDEWHITE',\n  'CDLGRAVESTONEDOJI',\n  'CDLHAMMER',\n  'CDLHANGINGMAN',\n  'CDLHARAMI',\n  'CDLHARAMICROSS',\n  'CDLHIGHWAVE',\n  'CDLHIKKAKE',\n  'CDLHIKKAKEMOD',\n  'CDLHOMINGPIGEON',\n  'CDLIDENTICAL3CROWS',\n  'CDLINNECK',\n  'CDLINVERTEDHAMMER',\n  'CDLKICKING',\n  'CDLKICKINGBYLENGTH',\n  'CDLLADDERBOTTOM',\n  'CDLLONGLEGGEDDOJI',\n  'CDLLONGLINE',\n  'CDLMARUBOZU',\n  'CDLMATCHINGLOW',\n  'CDLMATHOLD',\n  'CDLMORNINGDOJISTAR',\n  'CDLMORNINGSTAR',\n  'CDLONNECK',\n  'CDLPIERCING',\n  'CDLRICKSHAWMAN',\n  'CDLRISEFALL3METHODS',\n  'CDLSEPARATINGLINES',\n  'CDLSHOOTINGSTAR',\n  'CDLSHORTLINE',\n  'CDLSPINNINGTOP',\n  'CDLSTALLEDPATTERN',\n  'CDLSTICKSANDWICH',\n  'CDLTAKURI',\n  'CDLTASUKIGAP',\n  'CDLTHRUSTING',\n  'CDLTRISTAR',\n  'CDLUNIQUE3RIVER',\n  'CDLUPSIDEGAP2CROWS',\n  'CDLXSIDEGAP3METHODS']}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finol.data_layer.DatasetLoader import DatasetLoader\n",
    "from finol.optimization_layer.ModelTrainer import ModelTrainer\n",
    "from finol.evaluation_layer.ModelEvaluator import ModelEvaluator\n",
    "\n",
    "\n",
    "load_dataset_output = DatasetLoader().load_dataset()\n",
    "train_model_output = ModelTrainer(load_dataset_output).train_model()\n",
    "evaluate_model_output = ModelEvaluator(load_dataset_output, train_model_output).evaluate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training the Model**\n",
    "\n",
    "We next define a custom loss function called ``criterion`` for the following training process. In ``FinOL``, users have the flexibility to define their own custom loss functions.  This allows users to tailor the training process to their specific needs.  For example, users may want to define a custom loss function that includes risk measurement.\n",
    "\n",
    "Following that, we implement define the model architecture with the LSTM layer, specifying the input feature and output sizes based on the dataset characteristics obtained from the data loading stage.  The model is then moved to the designated device.\n",
    "\n",
    "An Adam optimizer is then chosen for training the network weights. In ``FinOL``, a comprehensive range of over 40 optimizers is available.\n",
    "\n",
    "The core training loop iterates over mini-batches from the training dataloader, performs forward, backward and optimization steps at each turn.  Validation loss is also computed periodically to select the best performing model checkpoint for later deployment.\n",
    "\n",
    "This covers the essential components involved in setting up and executing a deep learning workflow on financial data within the PyTorch framework as implemented in our tutorial.  We are now ready to kick off model training and analysis of results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}